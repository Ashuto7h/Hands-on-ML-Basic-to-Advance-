{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf83ab81",
   "metadata": {},
   "source": [
    "# Text Classification Using Random Forest\n",
    "\n",
    "In this notebook, we will perform text classification using the **Random Forest** classifier. The data is loaded from a CSV file named **complaints_processed.csv**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a31a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02e2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('complaints_processed.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78694eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset information\n",
    "print(f'--> There are {df.shape[0]} rows and {df.shape[1]} columns')\n",
    "print('\\n===========================================================\\n')\n",
    "print('--> Missing Values:\\n\\n', df.isna().sum())\n",
    "print('\\n===========================================================\\n')\n",
    "print('Product Counts:\\n\\n', df['product'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb7ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values as they are minimal\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Display class distribution in original dataset\n",
    "print('For Actual dataset:\\n\\n', df['product'].value_counts() * 100 / len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30ffed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling the data for faster processing\n",
    "data = df[['product', 'narrative']].sample(n=10000)\n",
    "\n",
    "# Display class distribution in sample dataset\n",
    "print('Sample dataset:\\n\\n', data['product'].value_counts() * 100 / len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b5f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean text data\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def text_clean(text):\n",
    "    \"\"\"\n",
    "    This function performs the following tasks:\n",
    "    1. Converts text to lowercase\n",
    "    2. Removes digits\n",
    "    3. Removes words with fewer than 3 characters\n",
    "    4. Removes stopwords\n",
    "    \"\"\"\n",
    "    clean_words = []\n",
    "    word_list = text.split()\n",
    "    for word in word_list:\n",
    "        word_l = word.lower().strip()\n",
    "        if word_l.isalpha() and len(word_l) > 3 and word_l not in stopwords:\n",
    "            clean_words.append(word_l)\n",
    "    return clean_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e01ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Term Document Matrix\n",
    "tfidf = TfidfVectorizer(analyzer=text_clean)\n",
    "x_tfidf = tfidf.fit_transform(data['narrative'])\n",
    "\n",
    "# Display shape of matrix\n",
    "print(\"Shape of Term Document Matrix:\", x_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad6b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_tfidf, data['product'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train RandomForest Classifier\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc_model = rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "prediction = rfc_model.predict(X_test)\n",
    "\n",
    "# Display Confusion Matrix and Classification Report\n",
    "print(\"Confusion Matrix:\\n\\n\", confusion_matrix(y_test, prediction))\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce0544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the normalized confusion matrix\n",
    "class_names = ['credit_card', 'credit_reporting', 'debt_collection', 'mortgages_and_loans', 'retail_banking']\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(rfc, X_test, y_test, display_labels=class_names, cmap=plt.cm.Blues, normalize='true')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
